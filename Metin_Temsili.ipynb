{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Metin Temsili (Text Representation)\n",
    "- Metin temsili ,bir metni sayısal veya başka türde bir formatta temsil etme işlemidir.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Bag of Words (BoW)\n",
    "- TF -IDF (Term frequency-nverse document frequency)\n",
    "- N-Gram modelleri \n",
    "- Word Embeddings\n",
    "- Transformer Tabanlı Metinli Temsili \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "# Bag of Words \n",
    "Bag of Words (BoW), metin verisi üzerinde kullanılan bir özellik çıkarım (feature extraction) yöntemidir. Bu yaklaşım, metindeki kelimeleri bir torba (bag) gibi ele alır ve kelimelerin sırasına ya da gramatikal yapılarına bakmaz. Sadece hangi kelimelerin metinde geçtiği ve her birinin ne kadar sıklıkla kullanıldığı dikkate alınır."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "## Kelime Sayımı (Word Count):\n",
    "BoW, her kelimenin metin içinde kaç defa geçtiğini sayarak bir özellik (feature) vektörü oluşturur. Bu vektör, her kelimenin bir sayısı ile temsil edilir.\n",
    "\n",
    "- Örnek:\n",
    "\n",
    "    - Diyelim ki elimizde şu iki cümle var:\n",
    "\n",
    "        - Cümle 1: \"Kediler çok sevimli.\"\n",
    "        - Cümle 2: \"Kediler çok hızlı koşuyor.\"\n",
    "        - Bu cümlelerden bir kelime kümesi (vocabulary) oluşturulur:  -  [\"Kediler\", \"çok\", \"sevimli\", \"hızlı\", \"koşuyor\"]\n",
    "\n",
    "    BoW temelli özellik vektörleri şöyle olur:\n",
    "\n",
    "    Cümle 1: [1, 1, 1, 0, 0]\n",
    "    Cümle 2: [1, 1, 0, 1, 1]\n",
    "    Her bir sayının anlamı, o kelimenin metinde kaç kere geçtiğidir."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "documents = [\n",
    "    \"Kedi evde\",\n",
    "    \"Kedi bahçede\"\n",
    "]\n",
    "vectorizer = CountVectorizer()\n",
    "# metin -> sayisal vektor\n",
    "x= vectorizer.fit_transform(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kelime kumesi:  ['bahçede' 'evde' 'kedi']\n"
     ]
    }
   ],
   "source": [
    "print(\"Kelime kumesi: \", vectorizer.get_feature_names_out())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vector temsili :  [[0 1 1]\n",
      " [1 0 1]]\n"
     ]
    }
   ],
   "source": [
    "print(\"vector temsili : \",x.toarray())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Note:\n",
    "### Temel Regex Söz Dizimi (Syntax)\n",
    "Regex ifadeleri belirli kurallara dayanır ve metin içinde desen aramak için kullanılır. Regex ifadelerinde kullanılan bazı yaygın semboller ve anlamları şunlardır:\n",
    "\n",
    "1.1 Karakter Sınıfları (Character Classes)\n",
    "- \\d: Rakam (0-9) - herhangi bir dijital karakteri temsil eder.\n",
    "- \\D: Rakam olmayan karakter (herhangi bir harf, sembol vb.).\n",
    "- \\w: \"Word\" (kelime karakteri) - harfler (a-z, A-Z), rakamlar (0-9) ve alt çizgi (_) içerir.\n",
    "- \\W: Kelime olmayan karakterler (boşluklar, noktalama işaretleri, vb.).\n",
    "- \\s: Boşluk karakteri (boşluk, tab, yeni satır, vb.).\n",
    "- \\S: Boşluk olmayan karakter.\n",
    "- \\b: Kelime sınırı (bir kelimenin başlangıcı ya da sonu).\n",
    "- \\B: Kelime sınırı olmayan bir yer.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Working on Real data set \n",
    "- Please check  kaggle - https://www.kaggle.com/code/zehranurmangal/learning-bag-of-words\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TF-IDF (Term Frequency-Inverse Document Frewuency)\n",
    "- Metin madenciliğinde ve bilgi erişiminde sıkça kullanılan bir özellik çıkarım yöntemidir.\n",
    "- kelimelerin belgeler içinde ne kadar önemli olduğunu belirlemek için kullanılır"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Term Frequency : Bir kelimenin bir belgede ne kadar sık geçtiğini ölçer\n",
    "- Bir kelimenin tüm belgelerdeki yaygınlığını ölçer .Bir kelimenin çok belgede geçiyorsa o kelime çok fazla bilgi sağlamaz\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "![Resim](images/image1.png)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import pandas as pd \n",
    "import numpy as np \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "documents = [ \n",
    "            \"Kedi çok tatlı bir hayvandır \",\n",
    "            \"Kedi ve köpekler çok tatlı hayvanlardır\",\n",
    "            \"Arılar bal üretir\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_vectorizer=TfidfVectorizer()\n",
    "\n",
    "#metinler -> sayısal \n",
    "X = tfidf_vectorizer.fit_transform(documents)\n",
    "\n",
    "feature_names = tfidf_vectorizer.get_feature_names_out()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['arılar' 'bal' 'bir' 'hayvandır' 'hayvanlardır' 'kedi' 'köpekler' 'tatlı'\n",
      " 've' 'çok' 'üretir']\n"
     ]
    }
   ],
   "source": [
    "print(feature_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TF-IDF vektor temsilleri: \n",
      "[[0.         0.         0.51741994 0.51741994 0.         0.3935112\n",
      "  0.         0.3935112  0.         0.3935112  0.        ]\n",
      " [0.         0.         0.         0.         0.45954803 0.34949812\n",
      "  0.45954803 0.34949812 0.45954803 0.34949812 0.        ]\n",
      " [0.57735027 0.57735027 0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.57735027]]\n"
     ]
    }
   ],
   "source": [
    "print(\"TF-IDF vektor temsilleri: \")\n",
    "vektor_temsili = X.toarray()\n",
    "print(vektor_temsili)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    arılar      bal      bir  hayvandır  hayvanlardır      kedi  köpekler  \\\n",
      "0  0.00000  0.00000  0.51742    0.51742      0.000000  0.393511  0.000000   \n",
      "1  0.00000  0.00000  0.00000    0.00000      0.459548  0.349498  0.459548   \n",
      "2  0.57735  0.57735  0.00000    0.00000      0.000000  0.000000  0.000000   \n",
      "\n",
      "      tatlı        ve       çok   üretir  \n",
      "0  0.393511  0.000000  0.393511  0.00000  \n",
      "1  0.349498  0.459548  0.349498  0.00000  \n",
      "2  0.000000  0.000000  0.000000  0.57735  \n"
     ]
    }
   ],
   "source": [
    "df_tf_ıdf = pd.DataFrame(vektor_temsili,columns=feature_names)\n",
    "print(df_tf_ıdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "arilat_tfıdf=df_tf_ıdf[\"arılar\"]\n",
    "arilat_mean_tfıdf = np.mean(arilat_tfıdf) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.19245008972987523\n"
     ]
    }
   ],
   "source": [
    "print(arilat_mean_tfıdf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Working on real data set\n",
    "Please check -> https://www.kaggle.com/code/zehranurmangal/learning-tf-idf\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# N-Gram Modelleri\n",
    "- Bir dil modelinde kullanılan kelime veya karakter dizisinin uzunluğunu belirten bir terimdir\n",
    "- Uni GRam 1-1 ayırır , Bi Gram olursa 2-2 ayırır cümleyi \n",
    "- Örnek ['bu bir örnek veridir']\n",
    "- Unigram : ['bu','bir','örnek','veridir']\n",
    "- Bi Gram : ['bu bir','örnek veridir']\n",
    "\n",
    "### Kullanım alanları\n",
    "- Metin Modelleme\n",
    "- Metin sınıflandırma \n",
    "- Metin üretimi \n",
    "- Metin Benzerliği\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "documents = [\n",
    "    \"Bu bir örnek metindir\",\n",
    "    \"bu örnek metin dogal dil işlemeyi gösterir.\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Unigram , bi gram ve trigram ->countvectorizer\n",
    "vectorizer_unigram = CountVectorizer(ngram_range=(1,1))\n",
    "vectorizer_bigram = CountVectorizer(ngram_range=(2,2))\n",
    "vectorizer_trigram = CountVectorizer(ngram_range=(3,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_unigram = vectorizer_unigram.fit_transform(documents)\n",
    "unigram_features = vectorizer_unigram.get_feature_names_out()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['bir' 'bu' 'dil' 'dogal' 'gösterir' 'işlemeyi' 'metin' 'metindir' 'örnek']\n"
     ]
    }
   ],
   "source": [
    "print(unigram_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['bir örnek' 'bu bir' 'bu örnek' 'dil işlemeyi' 'dogal dil'\n",
      " 'işlemeyi gösterir' 'metin dogal' 'örnek metin' 'örnek metindir']\n"
     ]
    }
   ],
   "source": [
    "X_bigram = vectorizer_bigram.fit_transform(documents)\n",
    "bigram_features = vectorizer_bigram.get_feature_names_out()\n",
    "print(bigram_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['bir örnek metindir' 'bu bir örnek' 'bu örnek metin'\n",
      " 'dil işlemeyi gösterir' 'dogal dil işlemeyi' 'metin dogal dil'\n",
      " 'örnek metin dogal']\n"
     ]
    }
   ],
   "source": [
    "X_trigram = vectorizer_trigram.fit_transform(documents)\n",
    "trigram_features = vectorizer_trigram.get_feature_names_out()\n",
    "print(trigram_features)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
